{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=/home/addinedu/runs/detect/train31/weights/best.pt source=/home/addinedu/Desktop/yolo/qtest/* save=true save_txt=true save_crop=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 모델 위치 - model=/home/addinedu/runs/detect/train31/weights/best.pt \n",
    "#바운딩 박스 치고 바운딩 박스 영역만 저장 - 위치: /home/addinedu/runs/detect/predict33/crops/box\n",
    "#크롭된 이미지 내에서 노란색이 차지하는 비율 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])  # BGR values\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue = hsvC[0][0][0]  # Get the hue value\n",
    "\n",
    "    # Handle red hue wrap-around\n",
    "    if hue >= 165:  # Upper limit for divided red hue\n",
    "        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([180, 255, 255], dtype=np.uint8)\n",
    "    elif hue <= 15:  # Lower limit for divided red hue\n",
    "        lowerLimit = np.array([0, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "    else:\n",
    "        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "yellow = [0, 255, 255]  # BGR 색상 공간에서의 노란색\n",
    "\n",
    "# 이미지 경로\n",
    "image_path = \"/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\"\n",
    "\n",
    "# 이미지 읽기\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "# HSV 색상으로 변환\n",
    "hsvImage = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 노란색의 범위 가져오기\n",
    "lowerLimit, upperLimit = get_limits(color=yellow)\n",
    "\n",
    "# 마스크 생성\n",
    "mask = cv2.inRange(hsvImage, lowerLimit, upperLimit)\n",
    "\n",
    "# 마스크를 이미지로 변환\n",
    "mask_ = Image.fromarray(mask)\n",
    "\n",
    "# 마스크 영역의 바운딩 박스 가져오기\n",
    "bbox = mask_.getbbox()\n",
    "\n",
    "# 바운딩 박스가 있으면 사각형 그리기\n",
    "if bbox is not None:\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "# 결과 표시\n",
    "cv2.imshow('frame', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yellow = [0, 255, 255]  # BGR 색상 공간에서의 노란색\n",
    "\n",
    "# 이미지 경로\n",
    "image_path = \"/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\"\n",
    "\n",
    "# 이미지 읽기\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "# HSV 색상으로 변환\n",
    "hsv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 노란색의 범위 가져오기\n",
    "lower_limit = np.array([20, 100, 100])\n",
    "upper_limit = np.array([30, 255, 255])\n",
    "\n",
    "# 마스크 생성\n",
    "mask = cv2.inRange(hsv_image, lower_limit, upper_limit)\n",
    "\n",
    "# 마스크를 이미지로 변환\n",
    "masked_image = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "# 이미지 출력\n",
    "plt.imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1191.629] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@1191.629] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m im\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#converting video streamed frames to HSV. which we will learn further\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m hsv\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Red Color\u001b[39;00m\n\u001b[1;32m     13\u001b[0m red_light\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m165\u001b[39m,\u001b[38;5;241m87\u001b[39m,\u001b[38;5;241m111\u001b[39m],np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cam=cv2.VideoCapture(0)\n",
    "\n",
    "while (1):\n",
    "    im= \"/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\"\n",
    "\n",
    "    #converting video streamed frames to HSV. which we will learn further\n",
    "    hsv=cv2.cvtColor(im,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Red Color\n",
    "    red_light=np.array([165,87,111],np.uint8)\n",
    "    red_dark=np.array([180,255,255],np.uint8)\n",
    "    \n",
    "    #Blue Color\n",
    "    blue_light=np.array([99,115,150],np.uint8)\n",
    "    blue_dark=np.array([120,255,255],np.uint8)\n",
    "    \n",
    "    #Yellow Color\n",
    "    yellow_light=np.array([55,60,200],np.uint8)\n",
    "    yellow_dark=np.array([60,255,255],np.uint8)\n",
    "    \n",
    "    #Green Color\n",
    "    green_light=np.array([65, 50, 50],np.uint8)\n",
    "    green_dark=np.array([77,255,255],np.uint8)\n",
    "    \n",
    "    #Range Specification\n",
    "    red=cv2.inRange(hsv,red_light,red_dark)\n",
    "    blue=cv2.inRange(hsv,blue_light,blue_dark)\n",
    "    yellow=cv2.inRange(hsv,yellow_light,yellow_dark)\n",
    "    green=cv2.inRange(hsv,green_light,green_dark)\n",
    "    \n",
    "    #Morphological Transformation using dilation\n",
    "    kernel=np.ones((15,15),\"uint8\")\n",
    "    \n",
    "    red=cv2.dilate(red,kernel)\n",
    "    res_red = cv2.bitwise_and(im,im, mask=red)\n",
    "    \n",
    "    blue=cv2.dilate(blue,kernel)\n",
    "    res_blue = cv2.bitwise_and(im,im, mask=blue)\n",
    "        \n",
    "    yellow=cv2.dilate(yellow,kernel)    \n",
    "    res_yellow = cv2.bitwise_and(im,im, mask=yellow)\n",
    "    \n",
    "    green=cv2.dilate(green,kernel)\n",
    "    res_green = cv2.bitwise_and(im,im, mask=green)\n",
    "    \n",
    "    #Tracking Red | Contour is used to recognize colored object in a video feed., hierarchy sets the ek ke andar ek wala thing for objects in a feed which is 2D\n",
    "    #enumerate fn: https://www.geeksforgeeks.org/enumerate-in-python/\n",
    "    (_,contours,hierarchy)=cv2.findContours(red,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    for _,contour in enumerate(contours):\n",
    "        area=cv2.contourArea(contour)\n",
    "        if area>300:\n",
    "            x,y,w,h=cv2.boundingRect(contour)\n",
    "            cnt=contours[len(contours)-1]\n",
    "            cv2.drawContours(im,cnt,-1,(0,0,255),3)\n",
    "            cv2.putText(im,\"Red\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255))\n",
    "            \n",
    "    #Tracking Blue\n",
    "    (_,contours,hierarchy)=cv2.findContours(blue,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    for _,contour in enumerate(contours):\n",
    "        area=cv2.contourArea(contour)\n",
    "        if area>300:\n",
    "            x,y,_,_=cv2.boundingRect(contour)\n",
    "            cnt=contours[len(contours)-1]\n",
    "            cv2.drawContours(im,cnt,-1,(255,0,0),2)\n",
    "            cv2.putText(im,\"Blue\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,0,0))\n",
    "            \n",
    "\n",
    "   #Tracking Yellow\n",
    "    (_,contours,hierarchy)=cv2.findContours(yellow,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    for _,contour in enumerate(contours):\n",
    "        area=cv2.contourArea(contour)\n",
    "        if area>300:\n",
    "            x,y,w,h=cv2.boundingRect(contour)\n",
    "            cnt=contours[len(contours)-1]\n",
    "            cv2.drawContours(im,cnt,-1,(0,255,255),2)\n",
    "            cv2.putText(im,\"Yellow\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255))\n",
    "            \n",
    "   #Tracking Green\n",
    "    (_,contours,hierarchy)=cv2.findContours(green,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    for _,contour in enumerate(contours):\n",
    "        area=cv2.contourArea(contour)\n",
    "        if area>300:\n",
    "            x,y,w,h=cv2.boundingRect(contour)\n",
    "            cnt=contours[len(contours)-1]\n",
    "            cv2.drawContours(im,cnt,-1,(0,255,0),2)\n",
    "            cv2.putText(im,\"Green\",(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0))\n",
    "        \n",
    "    blur=cv2.medianBlur(res_blue,15)\n",
    "    cv2.imshow(\"Blur\",blur)\n",
    "    cv2.imshow(\"Color Tracker\",im)\n",
    "    cv2.imshow(\"mask\",res_blue)\n",
    "    #cv2.imshow(\"median_red\",median1)\n",
    "    if cv2.waitKey(33)==27 and 0xFF!= ord('q'):\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주요 색상:\n",
      "[191 194 213]\n",
      "[19 17 15]\n",
      "[211 105 106]\n",
      "[158 156 170]\n",
      "[239 194  68]\n",
      "[118  48  48]\n",
      "[201  87  83]\n",
      "[130 123 133]\n",
      "[171 175 193]\n",
      "[42 36 33]\n",
      "[185 149  74]\n",
      "[186 154 146]\n",
      "[205 209 226]\n",
      "[193 107 107]\n",
      "[243 204  98]\n",
      "[205  96  93]\n",
      "[34 24 22]\n",
      "[81 29 28]\n",
      "[144 139 150]\n",
      "[154 107 101]\n",
      "[188 124 126]\n",
      "[174  77  75]\n",
      "[199 178 167]\n",
      "[162 166 184]\n",
      "[182 185 203]\n",
      "[11 10  8]\n",
      "[214 174  77]\n",
      "[182  94  93]\n",
      "[139  73  68]\n",
      "[209 116 118]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAAkCAYAAAAU7TnwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACPElEQVR4nO3cP2tVdxzH8c9Jb/71aqy2pjHBf6DNIEigQ6FLESe1z6HPpJMORegkuCiCmqnU+gxaKOgkbpZoI7WULBGUqqk1uTk+hJZfhgzf12s+3+/53cs98OYMt+v7vg8AUNbYbh8AANhdYgAAihMDAFCcGACA4sQAABQnBgCgODEAAMWJAQAobvB/L/zl10c7utFPP97K8s2rzfMfDga5ce7rfDocNu9Y/+RQ/ji62Dw/1m3lzJE7mZl82bzjt4f/5u6NV83zXZKvjizk4+mp5h3Pp/fmwfyJpOuadxw+eSp79u1vnv/rz9Vcu3Ipfb/dvOObCwtZ+mymeT4ZJoMv03UftG84vpSp2WPN89uv/87GD9eTzXfNO+Y/38zc6a3m+a1/+jxb3srobfOK3H36NMuPnzTPjyVZHIxnYge/yblTS1k8e755Pv12ptZWMrbZ/kUMx6cyO/woXePn6Ps+G7+vZLTxpvkMEwtzOXDu7A7OkKy93ZON0XjzGQaDQfbNzDSfIUm+v/xt7t/7uXn+2Pwwty9+kcmJ9uf7+cPpvH422Tz/bjTK6ov1bO/gv/1Ozs7n+MG55vkkOX35u/+8xpsBAChODABAcWIAAIoTAwBQnBgAgOLEAAAUJwYAoDgxAADFiQEAKE4MAEBxYgAAihMDAFCcGACA4sQAABQnBgCgODEAAMV1fd/3u30IAGD3eDMAAMWJAQAoTgwAQHFiAACKEwMAUJwYAIDixAAAFCcGAKA4MQAAxb0H5SxnQf5dBXcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def extract_main_colors(image_path, num_colors=30):\n",
    "    # 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 이미지를 1차원 배열로 변환\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    \n",
    "    # K-means 군집화 알고리즘을 사용하여 주요 색상 추출\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "    \n",
    "    # 클러스터 중심 색상 추출\n",
    "    main_colors = kmeans.cluster_centers_.astype(np.uint8)\n",
    "    \n",
    "    return main_colors\n",
    "\n",
    "# 이미지 경로\n",
    "image_path = \"/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\"\n",
    "\n",
    "# 주요 색상 추출\n",
    "main_colors = extract_main_colors(image_path)\n",
    "\n",
    "# 추출된 주요 색상 출력\n",
    "print(\"주요 색상:\")\n",
    "for color in main_colors:\n",
    "    print(color)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_color_palette(colors):\n",
    "    # 팔레트 생성\n",
    "    palette = np.zeros((50, len(colors) * 50, 3), dtype=np.uint8)\n",
    "    for i, color in enumerate(colors):\n",
    "        palette[:, i*50:(i+1)*50] = color\n",
    "    \n",
    "    # 팔레트 출력\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 주요 색상 팔레트 출력\n",
    "display_color_palette(main_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노란색이 차지하는 비율: 0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_color_ratio(image_path, target_color):\n",
    "    # 이미지를 RGB 형식으로 읽기\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 목표 색상을 Numpy 배열로 변환\n",
    "    target_color = np.array(target_color)\n",
    "    \n",
    "    # 이미지에서 목표 색상과 가까운 픽셀 식별\n",
    "    similar_pixels = np.all(np.isclose(image, target_color), axis=-1)\n",
    "    \n",
    "    # 목표 색상을 차지하는 비율 계산\n",
    "    color_ratio = np.sum(similar_pixels) / similar_pixels.size * 100\n",
    "    \n",
    "    return color_ratio\n",
    "\n",
    "# 테스트 이미지 경로\n",
    "image_path = \"/home/addinedu/runs/detect/predict33/crops/box/captured_image_20240510164337.jpg\"\n",
    "\n",
    "# 목표 색상\n",
    "target_color = [239, 194,  68]\n",
    "\n",
    "# 색상이 차지하는 비율 계산\n",
    "color_ratio = calculate_color_ratio(image_path, target_color)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"노란색이 차지하는 비율:\", color_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사한 노란색 범위:\n",
      "하한: [ 2 50 50]\n",
      "상한: [ 42 255 255]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_similar_yellow_range(rgb_color, tolerance=20):\n",
    "    # RGB 색상을 HSV 형식으로 변환\n",
    "    hsv_color = cv2.cvtColor(np.uint8([[rgb_color]]), cv2.COLOR_RGB2HSV)[0][0]\n",
    "\n",
    "    # 주어진 RGB 색상 주변의 노란색 범위 정의\n",
    "    lower_yellow = np.array([hsv_color[0] - tolerance, 50, 50])\n",
    "    upper_yellow = np.array([hsv_color[0] + tolerance, 255, 255])\n",
    "\n",
    "    return lower_yellow, upper_yellow\n",
    "\n",
    "# 주어진 RGB 색상\n",
    "rgb_color = [246, 203, 75]\n",
    "\n",
    "# 유사한 노란색 범위 찾기\n",
    "lower_yellow, upper_yellow = find_similar_yellow_range(rgb_color)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"유사한 노란색 범위:\")\n",
    "print(\"하한:\", lower_yellow)\n",
    "print(\"상한:\", upper_yellow)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyqt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
